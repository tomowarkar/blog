---
title: "今さら言語処理100本ノック #05 後半"
date: 2020-04-26T23:22:46+09:00
draft: true
toc: true
images:
tags:
  - nlp
  - python
---

### fuctions

- `read_cabocha` を`v3`に更新

```python
import re
class Morph:
    """cabochaの形態素解析結果
    Args:
        line (str): e.x. '名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ'
    Attributes:
        surface (str): 表層形
        base (str): 基本形
        pos (str): 品詞
        pos1 (str): 品詞細分類1
    """
    def __init__(self, line):
        pattern = r"^([^,]*?)\t([^,]*?),([^,]*?)(?:,[^,]*?){4},([^,]*?)(?:(?:,[^,]*?){2})?$"
        try:
            [(self.surface, self.pos, self.pos1, self.base)] = re.findall(pattern, line)
        except:
            raise Exception(f"Invalid line pattern: \n\t{repr(line)}", )

    def __str__(self):
        return self.surface

class Chunk:
    def __init__(self, dst):
        self.morphs = self.srcs = []
        self.dst = dst

    def  __str__(self):
        return "".join(list(map(str, self.morphs)))

def read_cabocha_v3(text):
    sentences = text.split("EOS\n")
    p = re.compile(r"\*\ (\d+)\ (-1|\d+)D\ \d+\/\d+\ -?\d+\.\d+")
    for sentence in sentences:
        dep = p.findall(sentence)
        if not dep:
            continue

        chunks = []
        for (index, dst) in dep:
            c = Chunk(int(dst))
            c.srcs = [int(f) for f, t in dep if t == index]
            chunks.append(c)

        cnt = -1
        for line in sentence.splitlines():
            if p.match(line):
                cnt += 1
                continue
            else:
                chunks[cnt].morphs.append(Morph(line))
        yield chunks

with open("neko.txt.cabocha") as f:
    text = f.read()

sentences = list(read_cabocha_v3(text))
```

### 45. 動詞の格パターンの抽出

今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．

動詞を含む文節において，最左の動詞の基本形を述語とする
述語に係る助詞を格とする
述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる
「吾輩はここで始めて人間というものを見た」という例文（neko.txt.cabocha の 8 文目）を考える． この文は「始める」と「見る」の２つの動詞を含み，「始める」に係る文節は「ここで」，「見る」に係る文節は「吾輩は」と「ものを」と解析された場合は，次のような出力になるはずである．

```
始める  で
見る    は を
```

このプログラムの出力をファイルに保存し，以下の事項を UNIX コマンドを用いて確認せよ．

コーパス中で頻出する述語と格パターンの組み合わせ
「する」「見る」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）

```python
f = lambda x, y: [m.base for m in x if m.pos == y]
text = ""
for sentence in sentences:
    verbs_and_pptls = [(f(chunk.morphs, "動詞"), f(chunk.morphs, "助詞")) for chunk in sentence]
    for i, (v, p) in enumerate(verbs_and_pptls):
        if v:
            pptls = sum([verbs_and_pptls[s][1] for s in sentence[i].srcs], [])
            pptls = " ".join(sorted(pptls))
            if not pptls:
                continue
            text += f"{v[0]}\t{pptls}\n"

with open("neko.txt.corpus", "w") as f:
    f.write(text)
```

```bash
$ head -n 10 neko.txt.corpus
生れる	で
つく	が と
泣く	で
する	だけ て は
始める	で
見る	は を
聞く	で
捕える	を
煮る	て
食う	て
```

```bash
$ cat neko.txt.corpus | sort -t "\t" -k 1 | uniq -c | sort -n -r | head -n 20
 560 云う	と
 436 する	を
 247 思う	と
 199 ある	が
 184 なる	に
 174 する	に
 172 見る	て
 120 する	と
 119 する	が
 108 する	に を
  93 見る	を
  90 見える	と
  79 する	て を
  60 する	が を
  58 もつ	を
  57 する	は
  57 する	て
  55 云う	を
  53 ある	の
  50 出来る	が

$ cat neko.txt.corpus | grep "^する\t" | sort -t "\t" -k 1 | uniq -c | sort -n -r | head -n 5
 436 する	を
 174 する	に
 120 する	と
 119 する	が
 108 する	に を

$ cat neko.txt.corpus | grep "^見る\t" | sort -t "\t" -k 1 | uniq -c | sort -n -r | head -n 5
 172 見る	て
  93 見る	を
  19 見る	て を
  19 見る	て て
  19 見る	から

$ cat neko.txt.corpus | grep "^与える\t" | sort -t "\t" -k 1 | uniq -c | sort -n -r | head -n 5
   3 与える	に を
   2 与える	て に は を
   1 与える	ば を
   1 与える	に に対して のみ は は も
   1 与える	て も を
```

### 46. 動詞の格フレーム情報の抽出

45 のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45 の仕様に加えて，以下の仕様を満たすようにせよ．

項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）
述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる
「吾輩はここで始めて人間というものを見た」という例文（neko.txt.cabocha の 8 文目）を考える． この文は「始める」と「見る」の２つの動詞を含み，「始める」に係る文節は「ここで」，「見る」に係る文節は「吾輩は」と「ものを」と解析された場合は，次のような出力になるはずである．

```
始める  で      ここで
見る    は を   吾輩は ものを
```

```python
def nlp100_46(sentence):
    text = ""
    f = lambda x, y: [m.base for m in x.morphs if m.pos == y]
    verbs = [f(chunk, "動詞") for chunk in sentence]
    for i, v in enumerate(verbs):
        if not v:
            continue
        pptls = [(sentence[src], f(sentence[src], "助詞")) for src in sentence[i].srcs if  f(sentence[src], "助詞")]
        if not pptls:
            continue
        pptls = sorted(pptls, key=lambda x: x[1][0])
        text += v[0] + "\t"
        text += " ".join([pptl[1][0] for pptl in pptls]) + "\t"
        text += " ".join([str(pptl[0]) for pptl in pptls]) + "\n"
    return text


print(nlp100_46(sentences[5]))
```

###

#### memo

`サ変接続`は`pos1`と`pos2`ででくるが、今回後者は対象外

```
$ cat neko.txt.cabocha | grep "サ変接続" | cut -f 2 | cut -d "," -f 1-3 | sort -r | uniq -c
4842 名詞,サ変接続,*
  21 名詞,接尾,サ変接続
```
